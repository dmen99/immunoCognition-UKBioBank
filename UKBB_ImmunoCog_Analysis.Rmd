---
title: "UKBB_ImmunoCog_Analysis"
author: "Daniel Mendelson"
date: "22/02/2022"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(stringr)
library(dplyr)
library(tidyr)
library(arsenal)
library(reticulate)
library(psych)
library(lubridate)
library(glue)
knitr::knit_engines$set(python = reticulate::eng_python)
reticulate::virtualenv_create(envname = "myreticulate", python = "/usr/bin/python3.8", packages = "pandas")

outputPath <- "/home/doodlefish/Documents/Research/LepageLab/immunologyAndSz/Analysis/immunoCognition/Outputs" # working directory to desired output location
setwd(outputPath)
date <- str_c(format(Sys.time(), "%m"), "_", format(Sys.time(), "%d"), "_", format(Sys.time(), "%Y")) # set todays date for easier output filenaming
```

# Biobank data
## Data Preperation
```{r dataPrep, echo=FALSE}
# import data -----------
df_all <- read_csv("/home/doodlefish/Documents/Research/LepageLab/immunologyAndSz/Data/ComputeCanadaData/Daniel_2022-02-23.csv") # import df
eidToRemove <- read_csv("/home/doodlefish/Documents/Research/LepageLab/immunologyAndSz/Data/ComputeCanadaData/eidToRemove-w45551_20220222.csv", col_names = "eid") # file with EID of participants who withdrew consent from UKBB
df_all <- df_all %>% 
  dplyr::filter(!(eid %in% eidToRemove)) # remove rows with eid in this file
# remove cases that haven't completed assessment 2
cat(paste("There are ", count(is.na(brain_timeCompleted)), "cases that have not completed imaging. These cases are will be removed."))
#df_all <- df_all %>% dplyr::filter(!(is.na(brain_timeCompleted))) # remove cases without imaging variables variable of interest is brain_timeCompleted, field code 21862
# remove cases that don't have CRP aliquot
cat(paste("Of with imaging data, there are ", count(is.na(crp_aliquot)), "cases that do not have crp-aliquot values. These cases are will be removed."))
#df_all <- df_all %>% dplyr::filter(!(is.na(crp_aliquot))) # remove cases without imaging variables variable of interest is brain_timeCompleted, field code 21862

df_small <- df_all[1:100,]
df <- df_small # specifies what df to use. In final analyses will want to use df_all but want to use smaller df while developing code.
rm(df_all, eidToRemove, df_small) # remove dataframes not in use
# sort(colnames(df))
# View(df)
```

```{r variableLists, echo=FALSE}
# List of variables by type --------------
  # factors # list of factors
  # cat_vars # list of categorical variables
  # num_vars # list of numeric variables
  brainVars <- starts_with("brain_", vars = colnames(df))
  cogVars <- starts_with("cog_", vars = colnames(df))
  dxVars <- starts_with("dx_", vars = colnames(df))
  medVars <- starts_with("med_", vars = colnames(df))
  dietVars <- starts_with("diet_", vars = colnames(df))
  # colnames(df[dietVars])
  # View(df[1:100, c(1,brainVars)])
```

# Quality control of date variables.
## N.b. variables names may require changing
```{r formatDates, echo=FALSE}
# Goal, return all cases when:
  ## time point 2 age < time point 0 age
  ## time point 2 asssessment date < time point 0 assessment date
  ## CRP assaydate < time point 0 date
birthYearCol <- contains("birthYear", vars = colnames(df))
df$birthYearModified <- df[birthYearCol]*10000 + 0702 # add july 02, 0702 as the middle day of the year
print("Added \'0702\' to all birth years, corresponding to the middle day of the year, July 02.")
head(df$birthYearModified)
df$birthYearModified <- as.Date(ymd(as.matrix(df$birthYearModified))) # convert YYYYMMDD to YYYY-MM-DD in date format

ageVars <- c(contains("age_assess", vars = colnames(df)))
date_assess2Cols <- date_assessCols[contains("2", vars = colnames(df_all[,date_assessCols]))] # find variable denoting the date of assessment 2
df_datesQC <- df[, c(1,contains("birthYear", vars = colnames(df)),dateVars, ageVars)] # create df subset with relevant vars only
# dim(df_datesQC) # check dimensions of this df
colnames(df_datesQC) # check the variable names in this subset
head(df_datesQC)
head(df$date_assess2_t2)

df_datesQC <- df_datesQC %>% 
  mutate("derivedAge_0" = round(interval(start = df_datesQC$birthYearModified, end = df_datesQC$date_assess0_t0)/years(1)), .after = "age_assess0_t0") %>% # compute age at assess 0
  mutate("difInAges_0" = (df_datesQC$"derivedAge_0" - df_datesQC$"age_assess0_t0"), .after = "derivedAge_0") %>% 
  mutate("derivedAge_2" = round(interval(start = df_datesQC$age_assess0_t0, end = df_datesQC$date_assess2_t2)/years(1)), .after = "age_assess2_t2") %>% # compute age at assess 2 from difference between assess 0 date and assess 2 date
  mutate("difInAges_2" = (df_datesQC$"derivedAge_2" - df_datesQC$"age_assess2_t2"), .after = "derivedAge_2")

cat(paste("Correlation between computed age at assessment 0 and age_assess0 is: ", cor(df_datesQC$derivedAge_0, df_datesQC$age_assess0_t0), ". \n\t Sum of the difference between both columns: ", sum(df_datesQC$difInAges_0), ". \n\t Max difference between both columns: ", max(df_datesQC$difInAges_0), ". \n Correlation between computed age at assessment 2 and age_assess2 is:", cor(df_datesQC$derivedAge_2, df_datesQC$date_assess2_t2), ". \n\t Sum of the difference between both columns: ", sum(df_datesQC$difInAges_2), ". \n\t Max difference between both columns: ", max(df_datesQC$difInAges_2)))
```
## Check if any age at assessment 2 is less than age at assessment 0
```{r dateQC, echo=FALSE}
Err_ageAss2 <- c() # array that will hold EIDs with age2 < age0
Err_dateAss2 <- c() # array that will hold EIDs with date2 < date0

j = 0
k = 0

for(i in 1:nrow(df_datesQC)){
    if(df_datesQC[i,colnames(select(df_datesQC, matches('age_assess+0')))] > df_datesQC[i,colnames(select(df_datesQC, matches('age_assess+2')))]){
      Err_ageAss2 <- c(Err_ageAss2, df_datesQC[i, 1])
      print(paste("EID: ", df_datesQC[i, 1], "has an AGE at ass. 2 (", df_datesQC[i,colnames(select(df_datesQC, matches('age_assess+2')))],  ") < AGE at ass. 0 (",  df_datesQC[i,colnames(select(df_datesQC, matches('age_assess+0')))], ")."))
      j = j + 1
      if(j == 0){
        print(paste("STOP CONDITION. EID: ", df_datesQC[i, 1], "AGE at ass. 2 (", df_datesQC[i,colnames(select(df_datesQC, matches('age_assess+2')))],  "), AGE at ass. 0 (",  df_datesQC[i,colnames(select(df_datesQC, matches('age_assess+0')))], ")."))
        stop()
      }
    }
    if(df_datesQC[i,colnames(select(df_datesQC, matches('date_assess+0')))] > df_datesQC[i,colnames(select(df_datesQC, matches('date_assess+2')))]){
      Err_dateAss2 <- c(Err_dateAss2, df_datesQC[i, 1])
      # print(paste("EID: ", df_datesQC[i, 1], "has an ASSESSMENT DATE 2 (", df_datesQC[i,colnames(select(df_datesQC, matches('date_assess+2')))],  ") < ASSESSMENT DATE 0 (",  df_datesQC[i,colnames(select(df_datesQC, matches('date_assess+0')))], ")."))
    } else{
      k = k+1
      if(k == 50000){
        print(paste("STOP CONDITION. EID: ", df_datesQC[i, 1], "has an ASSESSMENT DATE 2 (", df_datesQC[i,colnames(select(df_datesQC, matches('date_assess+2')))],  "), ASSESSMENT DATE 0 (",  df_datesQC[i,colnames(select(df_datesQC, matches('date_assess+0')))], ")."))
        stop()
      }
    }
}
  cat(paste("There are ", length(Err_ageAss2), "rows whose age assess 0 > age asses 2."))
  cat(paste("There are ", length(Err_dateAss2), "rows whose date assess 0 > date assess 2."))
# i=which(df_datesQC == 1000116)
# df_datesQC[i,]

if(max(df_datesQC$date_assess0_t0) < min(df_datesQC$crp_assaydate_t0)){
  cat(paste("CORRECT. All assessment 0 dates are less than all CRP assay dates. 
              \n\t Max assess 0 date: ", max(df_datesQC$date_assess0_t0), 
              "\n\t Min CRP assay date: ", min(df_datesQC$crp_assaydate_t0)))
} else {
  cat(paste("WARNING. It is possible that some assessment 0 dates are less than some CRP assay dates. Since max assess 0 date > min CRP assay date.  
              \n\t Max assess 0 date: ", max(df_datesQC$date_assess0_t0), 
              "\n\t Min CRP assay date: ", min(df_datesQC$crp_assaydate_t0),
            "\n It is recommended to compare each instance's assessment 0 date to its CRP assay date to ensure quality of the data."))
} # !! replace variable names with generalizable var name

min(df_datesQC[,colnames(select(df_datesQC, matches('assaydate+0')))])
(df_datesQC)
View(df_datesQC[df_datesQC$eid %in% Err_ageAss2,])
```
# Add columns
## Add columns for any diagnosis or medication
```{r addColumns, echo=FALSE}
# Create column identifying if have any diagnoses of interest or medication of interest  -------------------------
## Diagnosis
dx_col <- apply(df, TRUE, function(r) any (r %in% dxVars))
df %>% 
  mutate(anyDx = case_when(
    for(i in dxVars){
      df[i] == TRUE
      print(i)
    }
  ))
colnames(df)[diagnosisVars]

## Medication
# repeat code above for medication
```
## Add dummy code variables
```{r createDummyCodes, echo=FALSE}
# goal: 
## -convert a single categorical variable with >2 categories to dummy codes;
## -have a list with all dummy codes relevant to each variable

# Vars to dummy code

```
## Add column controlling for head size
Note: Controlling for head size is intended for brain volumes that are known to be affected by size. See "UK Biobank Brain Imaging Documentation", p. 19.
```{r controlForHeadSize, echo=FALSE}
controlHeadSize <- function(df, brainVarName){ # n.b. this is intended for brain volumes that are known to be affected by total brain size. See UK Biobank Brain Imaging Documentation, p. 19.
  newColName <- glue(brainVarName, "_headScaleCorrected")
  df <- df %>% # add column for brain volume * brain head scale, controls for brain size
  mutate_(newColName = {{ brainVarName }} * "brain_headScale")
} # takes 'df' - dataframe; 'brainVarName' - name of brain volume to control for brain size
df <- controlHeadSize(df, "brain_vol-hippocamp-L")
df <- controlHeadSize(df, "brain_vol-hippocamp-R")
```
# Analyses
Use '_headScaleCorrected' for brain volumes known to be affected by head size.
## Descriptive Stats
```{python Descriptive_Stats, echo=FALSE}
import pandas as pd
import os

os.chdir(r.outputPath)
fileName = "".join(("UKBBdescriptiveStats_", r.date, ".csv"))

r.df.describe(include='all')
r.df.describe(include='all').to_csv(fileName)
print("The file ", fileName, "was saved to \'", os.getcwd(), "\'.")
```
## Assumption checks
```{r Assumption_Checks, echo=FALSE}
# see 536 lab 3, lecture notes week 3
assumptionTest <- function(df, dfModel, y){ # 'df' is dataframe. 'dfModel' is the lm model of interest. 'y' is the outcome variable in a string.
## Assumption tests for STEMModel ----------------
  colNumofY <- which(colnames(df) == y)
  cat(paste("Assumption tests for the given data and model with dependent variable '", y, "'"))
  ### Normality  ---
  ## check skew and kurtosis
  cat("\n 1. Normality.") 
  cat("\n 1.a \t Skew and kurtosis.")
  skew <- skew(df[[colNumofY]]) # determines the skew of the dependent variable's distribution. N.b., the double square brackets '[[]]' is ESSENTIAL for getting the correct results--single brackets '[]' will return inaccurate results.
  SE_skew <- sqrt(5/dim(df)[1])# Standard error for the skewness
  t_skew <- skew/SE_skew # t value for the skewness in the dependent variable's distribution
  
  kurtosis <- kurtosi(df[[colNumofY]]) # determines the skew of the dependent variable's distribution
  SE_kurtosis <- sqrt(24/dim(df)[1]) # Standard Error for the kurtosis
  t_kurtosis <- kurtosis/SE_kurtosis # t value for the kurtosis in the dependent variable's distribution
  
  if(abs(t_skew) > 3.2){ # checks if the t-value for skewness is greater than the critical t-value 
    cat(paste("\n \t\t !! Skewness (", skew, ") is significantly different from 0 (|t| = ", abs(t_skew), "> 3.2). Outcome variable is not normal."))
  } else {
    cat(paste("\n \t\t Skewness (", skew, ") is not significantly different from 0 (|t| = ", abs(t_skew), "< 3.2). Outcome variable may be normal."))
  }
  
  if(abs(t_kurtosis) > 3.2){ # checks if the t-value for kurtosis is greater than the critical t-value 
    cat(paste("\n \t\t !! Kurtosis (", kurtosis, ") is significantly different from 0 (|t| = ", abs(t_kurtosis), "> 3.2). Outcome variable is not normal."))
  } else {
    cat(paste("\n \t\t Kurtosis (", kurtosis, ") is not significantly different from 0 (|t| = ", abs(t_kurtosis), "< 3.2). Outcome variable may be normal."))
  }
  
  ## Quantile-quantile plot; points should follow the reference line
  cat("\n 1.b \t Quantile-quantile plot:")
  QQPlot <- plot(dfModel,2, main = "1.b Quantile-Quantile plot")
  cat("\n \t\t If the data is normal, points on the Q-Q plot will follow the reference line.")
  # ggplot(df, aes(sample = y))+ stat_qq() + stat_qq_line()+ ggtitle("Q-Q Plot for interest in STEM") # alternative QQ plot
  ###
  
  ### Linearity and homoscedasticity ---
  ## residual plot
  cat("\n 2. Linearity and homoscedasticity.")
  cat("\n 2.a \t Residual plot:")
  residualPlot <- plot(STEMModel, 1, main = "2.a Residual plot") # x is fitted values, y is residuals
  # plot(dfModel, 3) # alternative to the plot above. Difference is that y-axis is the sqrt(abs(residuals))
  cat("\n \t\t If the data is linear, best fit of residuals (red line) should be linear.")
  cat("\n \t\t If the data is homoscedastic, range of residuals should be equivalent/comparable at all values of the 'fitted values' (i.e. y-hat).")
  ## 
  ###
  
  ### Multicollinearity ---
  ## Tolerance
  cat("\n 3. Testing multicollinearity: tolerance.")
  cat("\n if R^2 is high but there are few significant ")
  cat("\n 3.a \t Variance Inflation Factors:")
  vifPlot <- vif(dfModel, main = "3.a Variance Infation Factors")
  cat("\n \t\t If any VIF value is above 10, this indicates that the multicollinearity is not true.")
  
  ## correl matrix
  cat("\n 3.b \t Correlation matrix:")
  print(cor(df)) # cats correlation matrix of all the predictors
  cat("\n \t\t Ensure that all regression coefficients are insignificant predictors though overall model is significant.")
  cat("\n \t\t N.b. this is less formal than Tolerance and VIF analysis above.")
  ## check that all regression coefficients are insignificant predictors though overall model is significant -- though this is less formal
  ###
  
  ### Model correctly specified ----
  cat("\n 4 Correct specification of model.") 
  cat("\n 4.a \t Added-variable plots (aka partial-regression):")
  addedVarPlot <- avPlots(dfModel, main = "4.a Added-variable plots") # if slope is 0 then the predictor is not predicting unique variance in the model. SLope of lines should be equivalent to the regression coefs in the model.
  cat("\n \t\t The closer to 0 is the slope, the less unique variance this predictor is explaining in the model (slope of 0 = explaining no unique variance). N.b., Slope of lines is equivalent to the regression coefs in the model.")
  # summary(dfModel) # slope of line
  cat("\n \t\t Remove variable that is not predicting unique variance. Do so one at a time--excluding the one with a slope closest to 0 if applicable--and do so only at the end!")
  # !! only remove predictors at the end !!
  ###
  
  ### Outliers (i.e. influencers) ---
  cat("\n 5. Outlier analysis.")
  ## Evaluate influence
  cat("\n 5.a \t Evaluating influence.") 
  cat("\n 5.a.i \t\t Plot of Cook's distances:")
  cooksDistance <- plot(dfModel, 4, main = "5.a.i Cook's distance plot") # plot of Cook's distance
  cat("\n \t\t\t ") # Note what should be looked for.
  
  # Influence plot
  cat("\n 5.a.ii \t\t Influence Plot:")
  influencePlot <-influencePlot(dfModel, main="5.a.ii Influence Plot")
  cat("\n \t\t\t Consider removing the point(s) with large influence.") # Note what should be looked for.
  cat("\n \t\t\t Note. The larger the circle, the more influence the observation has. Studentized residuals indicate distance; hat-values indicate leverage") # Note what should be looked for.

  cat("\n 5.a.iii \t Influence Index Plot:")
  infIndex <- infIndexPlot(dfModel, main = "5.a.iii Influence Index Plot")
  
  allPlots <- 
    QQPlot + facet_wrap(~ carb, nrow = 1) + theme(legend.position = "none") +
    ggtitle("Test")
  
  # residualPlot, vifPlot, addedVarPlot, cooksDistance, influencePlot, infIndex

  # list(QQPlot, residualPlot, vifPlot, addedVarPlot, cooksDistance, influencePlot, infIndex)
  # list(plot(dfModel,2, main = "1.b Quantile-Quantile plot"), plot(STEMModel, 1, main = "2.a Residual plot"),vif(dfModel, main = "3.a Variance Infation Factors"),avPlots(dfModel, main = "4.a Added-variable plots"), plot(dfModel, 4, main = "5.a.i Cook's distance plot"),influencePlot(dfModel, main="5.a.ii Influence Plot"), infIndexPlot(dfModel, main = "5.a.iii Influence Index Plot"))
}
```
### Normality
```{r normalityCheck, echo=FALSE}
normalityCheck <- function(df, y){  
  colNumofY <- which(colnames(df) == y)
  cat(paste("Assumption tests for the given data and model with dependent variable '", y, "'"))
  ### Normality  ---
  ## check skew and kurtosis
  cat("\n 1. Normality.") 
  cat("\n 1.a \t Skew and kurtosis.")
  skew <- skew(df[[colNumofY]]) # determines the skew of the dependent variable's distribution. N.b., the double square brackets '[[]]' is ESSENTIAL for getting the correct results--single brackets '[]' will return inaccurate results.
  SE_skew <- sqrt(5/dim(df)[1])# Standard error for the skewness
  t_skew <- skew/SE_skew # t value for the skewness in the dependent variable's distribution
  
  kurtosis <- kurtosi(df[[colNumofY]]) # determines the skew of the dependent variable's distribution
  SE_kurtosis <- sqrt(24/dim(df)[1]) # Standard Error for the kurtosis
  t_kurtosis <- kurtosis/SE_kurtosis # t value for the kurtosis in the dependent variable's distribution
  
  if(abs(t_skew) > 3.2){ # checks if the t-value for skewness is greater than the critical t-value 
    cat(paste("\n \t\t !! Skewness (", skew, ") is significantly different from 0 (|t| = ", abs(t_skew), "> 3.2). Outcome variable is not normal."))
  } else {
    cat(paste("\n \t\t Skewness (", skew, ") is not significantly different from 0 (|t| = ", abs(t_skew), "< 3.2). Outcome variable may be normal."))
  }
  
  if(abs(t_kurtosis) > 3.2){ # checks if the t-value for kurtosis is greater than the critical t-value 
    cat(paste("\n \t\t !! Kurtosis (", kurtosis, ") is significantly different from 0 (|t| = ", abs(t_kurtosis), "> 3.2). Outcome variable is not normal."))
  } else {
    cat(paste("\n \t\t Kurtosis (", kurtosis, ") is not significantly different from 0 (|t| = ", abs(t_kurtosis), "< 3.2). Outcome variable may be normal."))
  }
} # takes 'df' - dataframe; 'y' variable of interest
```
#### Normality corrections
!! Vars in code may need to be renamed !!
```{r normalityCorrections, echo=FALSE}
normCorrection <- function(df, xName, correctionType){
  xColNum <- which(colnames(df) == xName)
  if(correctionType == "tert"){
    tertileValues <- quantile(df[xColNum], c(0:3/3), na.rm = T) # find tertile values
    newColName <- glue(xName, "_tert")
    df <- df %>% 
      mutate_(newColName = cut({{ xName }},
                       breaks = .tertileValues,
                       labels = FALSE,
                       include.lowest = T), 
             .after = {{ xName }})
    cat(paste("The tertiles for ", xName, "are: \n\t", tertileValues))
  } else if (correctionType == "log") {
    newColName <- glue(xName, "_log")
    df <- df %>% 
      mutate(newColName = log(df[xColNum]), .after = xName)
  } else {
    cat(paste("Error. '", correctionType, "' is not a valid correction type. Accepted values are: \n\t'tert' for tertiles; \n\t'log' for logarithmic. \nNo changes were made to the dataframe for the variable ", xName, "."))
  }
  return(df)
} # takes df: dataframe; xName: name of the variable to correct; correctionType: how the variable should be corrected (possible values: 'tert' tertile, 'log' logarithmic. Returns df with the corrected variable after the original variable.

df <- normCorrection(df, xName = "crp_aliquot_t0", correctionType = "tert")
df <- normCorrection(df, xName = "age_assess0_t0", correctionType = "tert")

head(as.data.frame(df$age_assess0_t0))
is.numeric(df$age_assess0_t0)
xName <- "age_assess0_t0"
xColNum <- which(colnames(df) == xName)
tertileValues <- quantile(df[xColNum], c(0:3/3), na.rm = T) # find tertile values
df <- df %>% 
      mutate(newColName = cut(age_assess0_t0,
                       breaks = tertileValues,
                       labels = FALSE,
                       include.lowest = T), 
             .after = xName)
table(df$age_tert)
df <- df %>% 
      mutate(age_tert = cut(age_assess0_t0,
                       breaks = tertileValues,
                       labels = c("Low", "Medium", "High"),
                       include.lowest = T), 
             .after = xName)

# add column denoting tertile score
```
### Linearity
```{r linearityChecks, echo=FALSE}

```
### Homoscedasticity
```{r homoscCheck, echo=FALSE}

```

## Simple Correlation function
```{r pearsonCor, echo=FALSE}

```

## Data reduction
-PCA assumptions: 
--linear relationship between components
```{r PCA, echo=FALSE}
PCA <- function(){

}
simpleFunction(2)
# DATA REDUCTION --------------------
## Correlations
### Diet variables
print("To conduct correlation, these variables must be numeric. Must determine what to do with the special values that are currently being recoded.")
cor(df[dietVars])

### Cognition variables
# Recode cog_TMT-alphanumDuration_t2 == "trail not completed" to NA
length(which(df$`cog_TMT-alphanumDuration_t2`== "trail not completed"))
# Recode cog_TMT-numericDuration_t2 == "trail not completed" to NA
length(which(df$`cog_TMT-numericDuration_t2`== "trail not completed"))
# Recode cog_numMem-maxDigitRemem_t2 == "abandoned" to NA
length(which(df$`cog_numMem-maxDigitRemem_t2`== "abandoned"))

## PCA (see 536 lecture notes week 10) ---------
### assumption checks ---------
## PCA example, cognition variables ----------
### PCA 1 - standardize numeric data 
df_zcog <- df[cogVars] %>% 
  as_tibble() %>% 
  mutate(across(where(is.numeric), scale))
describe(df_zcog) # ensure that mean is 0, sd 1

### PCA 2 - number of components to retain
#### eigenvalue method (eigen value > 1, suggested to keep)
zcog_eigenValues <- eigen(cor(df_zcog))$values
for(i in zcog_eigenValues){
  if(i > 1){
    cat("Suggestion to keep component i. Eigenvalue: ", i)
  } else {
    cat("Suggestion to exclude component i. Eigenvalue: ", i)
  }
}

#### scree plot (components before the elbow, suggested to keep)
plot(zcog_eigenValues,
     xlab = "Prinicipal component",
     ylab = "Eigenvalue",
     type = 'b',
     main = "Scree plot") + 
  abline(h = 1)

#### proportion of variance explained
zcog_PCAvarExplained <- zcog_eigenValues/length(df[cogVars])
zcog_PCAvarExplained
print("Looking for components that, together, can explain >80% of variance.")

## Tertile - Cognition
### Raw scores
### PCA components

```

```{r subsetCreation, echo=FALSE}
# Make different data subsets:
## N.b. should only subset when the main df has all the columns necessary for analysis
df_dx <- df %>% 
  group_by(across(any_of(dxVars))) %>% 
  summarize(median(crp_aliquot_t0))
df_dx
df_noDx <- df %>% filter(if_any(diagnosisVars[1] == "FALSE"))

df_noDx <- df %>% filter(diagnosisVars[1] == "FALSE")
View(df[1:100,c(1,diagnosisVars)])

df_noDx <- df %>% filter(if_all(diagnosisVars == FALSE)) # remove participants with diagnoses from dataframe 
df_onlyDx <- df %>% filter() # remove participants without diagnoses from dataframe 
df_noMed <- df %>% filter() # remove participants taking meds from dataframe 
df_onlyMed <- df %>% filter() # remove participants not taking meds from dataframe 
df_old <- df %>% filter() # keeps only participants in the top tertile of age
df_young <- df %>% filter() # keeps participants in the bottom tertile of age

```

## Function to make appropriate expression for stats::LM functions
```{r mediationFunction, echo=FALSE}
createLMExpression <- function(varNames, X, Y, M, C){
  colNumsPredictors <- c()
  for(i in c(X, M, C)){
    colNum <- which(varNames == i)
    colNumsPredictors <- append(colNumsPredictors, colNum)
  } # get column numbers for the relevant predictor variables
  varNames <- names(df[[colNumsPredictors]])
  LMpredictors <- toString(paste(varNames, "+ ", collapse = ''))
  LMpredictors <- substr(LMpredictors, 1, nchar(LMpredictors)-3)
  model <- paste(Y, " ~ ", LMpredictors)
  return(model)
} # Input: 'varNames' - list of variable names in the dataframe to be analysed. Is given by the function colnames(df); 'Y' - name of the dependent variable; 'X' - name of the independent variable; 'M' - name of mediators mediators; 'C' - list of covariate variable names;
```

## Correlation analyses functions
```{r mediationFunction, echo=FALSE}

```
## Mediation functions analyses
!! Will need to determine how to include covariate variables in this !! -- perhaps just include when (M ~ X) and when (Y ~ X + M)
--As of March 12, 2022: uses all the covariates in the a path and the c path. See 'mediation: R package for Causal Mediation Analysis' (Tingley et al., 2014)
For help with interpretation, see PSYC 536 lab 5 script.
Using package: mediation
```{r mediationFunction, echo=FALSE}
library(mediation)
# where M: continuous mediator; X: independent variable; Y: continuous dependent variable; C: covariates
runMediation <- function(df, X, Y, M, C){
  mediatorModelExpression <- createLMExpression(varNames = colnames(df), X = X, Y = M, M = "", C = C) # mediator model: predict M from X and C
  outcomeModelExpression <- createLMExpression(varNames = colnames(df), X = X, Y = Y, M = M, C = C) # outcome model: predict Y from X, M and C
  
  mediatorModel <- lm(eval(parse(text = mediatorModelExpression)), data = df) 
  outcomeModel <- lm(eval(parse(text = outcomeModelExpression)), data = df)
  mediation_out <- mediation::mediate(mediatorModel, outcomeModel, treat = X, mediator = M, boot = T)
  return(mediation_out)
} # This function runs the mediation analyses and returns the mediation model. Input: 'df' - dataframe; 'X' - name of independent variable; 'Y' - name of dependent variable; 'C' - a list of covariate variable names in string form.

mediationOutputs <- function(mediation_out, M, confounderSameDirection){
  summary <- summary(mediation_out)
  sensitivityAnalysis <- medsens(mediation_out, rho.by = .1, effect.type = "indirect")
  plot(sensitivityAnalysis, sens.par = "R2", r.type = "total", sign.prod = confounderSameDirection, main = M) # plots for R2. N.b. 'sign.prod', does the hypothesized confounder affect the mediator and outcome variables in the same direction or in different directions? If same then sign.prod = positive, else, = negative. See mediationR2 for details. 
} # Makes output for the mediation analyses, including summary, sensitivity analysis in tabular and plot forms. Input: 'mediation_out' - the mediation model returned by the runMediation function; 'M' - the name of the mediator variable (as string); 'confounderSameDirection' - does the hypothesized confounder affect the mediator and outcome in the same direction?, if true then "positive" is appropriate, if false then "negative" is appropriate.
```
Using package: RMediation
```{r RMediationFunction, echo=FALSE}
library(RMediation)
# see psyc 536 lecture 5 notes
runRMediation <- function(df, X, Y, M, C){
  totModelExpression <- createLMExpression(varNames = colnames(df), X = X, Y = Y, M = "", C = C) # total model: predict Y from X and C
  aPathExpression <- createLMExpression(varNames = colnames(df), X = X, Y = M, M = "", C = C) # a path model: predict M from X and C
  bPathExpression <- createLMExpression(varNames = colnames(df), X = X, Y = Y, M = M, C = C) # b path & direct path model: predict Y from X, M, and C
  
  # total effect
  totModel <- lm(eval(parse(text = totModelExpression)), data = df)
  cat("'total model' linear model expression: \n\t", totModelExpression)
  print(summary(totModel))
  
  # a path -- predict M from X
  aModel <- lm(eval(parse(text = aPathExpression)), data = df)
  cat("'a path' linear model expression: \n\t", aPathExpression)
  print(summary(aModel))
  
  # b path -- predict Y from X, M and C
  bModel <- lm(eval(parse(text = bPathExpression)), data = df)
  cat("'b path' linear model expression: \n\t", bPathExpression)
  print(summary(bModel))
  
  a <- coef(aModel)[which(names(coef(aModel)) == X)] # want coef for effect of X on M
  a.se <- coef(summary(aModel))[which(names(coef(aModel)) == X),2] # want S.E. of the regression coef of X on M. N.b. index is [row of X, column of standard errors of estimate]
  b <- coef(bModel)[which(names(coef(bModel)) == M)] # want coef for effect of M on Y
  b.se <- coefficients(summary(bModel))[which(names(coef(bModel)) == M),2] # want coef for effect of M on Y
  
  medci(mu.x = a, mu.y = b, se.x = a.se, se.y = b.se, rho = 0, alpha = .05, plot = T, plotCI = T)
  #format output somehow
} # input: 'df' - dataframe containing all relevant variables; 'X' - name of the predictor variable; 'Y' - name of the outcome variable; 'M' - name of the mediator variable; 'C' - list of names of covariate variables
```
## Conduct analyses and return outputs
```{r analysisSandBox, echo=FALSE}
X <- "crp_aliquot_t0" # name of independent variable
Y <- "blood_vitD_t0" # name of dependent variable
M <- "crp_timeFasting_t0"
C <- c("demgraph_sex_t0", "ses_townsend_t0", "age_assess0_t0")

mediation_out <- runMediation(df, X = X, Y = Y, M = M, C = C)
summary(mediation_out)

mediatorModelExpression <- createLMExpression(varNames = colnames(df), X = X, Y = M, M = "", C = C) # mediator model: predict M from X and C
outcomeModelExpression <- createLMExpression(varNames = colnames(df), X = X, Y = Y, M = M, C = C) # outcome model: predict Y from X, M and C
mediatorModel <- lm(eval(parse(text = mediatorModelExpression)), data = df) 
outcomeModel <- lm(eval(parse(text = outcomeModelExpression)), data = df)
mediation_out <- mediation::mediate(mediatorModel, outcomeModel, treat = X, mediator = M, boot = T)

```

```{r Analyses, echo=FALSE}
X <- "CRP_aliquot_t0" # name of independent variable
Y <- "cogGlobal" # name of dependent variable
mainCovars <- c("age_assess0", "BMI", "ses_townsend") # list of all main covariates to control for

# Correlations
## Models without covariates
cor0_noC <- lm(Y ~ X, data = df)
cor0 <- lm(Y ~ X + mainCovars, data = df)

## Models with covariates

# Mediations
## Models without covariates
model0_noC <- runMediation(df = df, X = X, Y = Y, M = "brain_vol-brainSegNoVent", covars = "") # model between CRP, whole brain volume, general cog
model1a_noC <- runMediation(df = df, X = X, Y = Y, M = "brain_vol-hippocamp-L", covars = "") # model between CRP, L hippocamp, memory
model1b_noC <- runMediation(df = df, X = X, Y = Y, M = "brain_vol-hippocamp-R", covars = "") # model between CRP, L hippocamp, memory

## Models with covariates
model0 <- runMediation(df = df, X = X, Y = Y, M = "brain_vol-brainSegNoVent", covars = mainCovars) # model between CRP, whole brain volume, general cog
model1a <- runMediation(df = df, X = X, Y = Y, M = "brain_vol-hippocamp-L", covars = mainCovars) # model between CRP, L hippocamp, memory
model1b <- runMediation(df = df, X = X, Y = Y, M = "brain_vol-hippocamp-R", covars = mainCovars) # model between CRP, L hippocamp, memory

listMedModels <- c(model0_noC, model0, model1a_noC, model1a, model1b_noC, model1b)
for(i in listMedModels){
  mediationOutputs(i) # runs the mediationOutput function for each model in the list models list
}

# Repeat above for different subsets of data (i.e. with and with diagnoses, drugs...)
```