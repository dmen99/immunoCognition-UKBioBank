---
title: "UKBB_ImmunoCog_Analysis"
author: "Daniel Mendelson"
date: "22/02/2022"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(stringr)
library(dplyr)
library(tidyr)
library(arsenal)
library(reticulate)
library(psych)
library(lubridate)
library(glue)
library(knitr)
knitr::knit_engines$set(python = reticulate::eng_python)
reticulate::virtualenv_create(envname = "myreticulate", python = "/usr/bin/python3.8", packages = "pandas")

outputPath <- "/home/doodlefish/Documents/Research/LepageLab/immunologyAndSz/Analysis/immunoCognition/Outputs" # working directory to desired output location
setwd(outputPath)
date <- str_c(format(Sys.time(), "%m"), "_", format(Sys.time(), "%d"), "_", format(Sys.time(), "%Y")) # set todays date for easier output filenaming
```

# 0 - Functions

## Descriptive Stats function

```{python DescriptiveStatsFx, echo=FALSE}
import pandas as pd
import os as os
  
def descriptiveStats(df, toSave):
  if(toSave == True):
    os.chdir(r.outputPath)
    fileName = "".join(("UKBBdescriptiveStats_", r.date, ".csv"))
    df.describe(include='all').to_csv(fileName)
    print("The file ", fileName, "was saved to \'", os.getcwd(), "\'.")
  return df.describe(include='all')
```

## Assumption checks

```{r Assumption_Checks, echo=FALSE}
# see 536 lab 3, lecture notes week 3
assumptionTest <- function(df, dfModel, y){ # 'df' is dataframe. 'dfModel' is the lm model of interest. 'y' is the outcome variable in a string.
## Assumption tests for STEMModel ----------------
  colNumofY <- which(colnames(df) == y)
  cat(paste("Assumption tests for the given data and model with dependent variable '", y, "'"))
  ### Normality  ---
  ## check skew and kurtosis
  cat("\n 1. Normality.") 
  cat("\n 1.a \t Skew and kurtosis.")
  skew <- skew(df[[colNumofY]]) # determines the skew of the dependent variable's distribution. N.b., the double square brackets '[[]]' is ESSENTIAL for getting the correct results--single brackets '[]' will return inaccurate results.
  SE_skew <- sqrt(5/dim(df)[1])# Standard error for the skewness
  t_skew <- skew/SE_skew # t value for the skewness in the dependent variable's distribution
  
  kurtosis <- kurtosi(df[[colNumofY]]) # determines the skew of the dependent variable's distribution
  SE_kurtosis <- sqrt(24/dim(df)[1]) # Standard Error for the kurtosis
  t_kurtosis <- kurtosis/SE_kurtosis # t value for the kurtosis in the dependent variable's distribution
  
  if(abs(t_skew) > 3.2){ # checks if the t-value for skewness is greater than the critical t-value 
    cat(paste("\n \t\t !! Skewness (", skew, ") is significantly different from 0 (|t| = ", abs(t_skew), "> 3.2). Outcome variable is not normal."))
  } else {
    cat(paste("\n \t\t Skewness (", skew, ") is not significantly different from 0 (|t| = ", abs(t_skew), "< 3.2). Outcome variable may be normal."))
  }
  
  if(abs(t_kurtosis) > 3.2){ # checks if the t-value for kurtosis is greater than the critical t-value 
    cat(paste("\n \t\t !! Kurtosis (", kurtosis, ") is significantly different from 0 (|t| = ", abs(t_kurtosis), "> 3.2). Outcome variable is not normal."))
  } else {
    cat(paste("\n \t\t Kurtosis (", kurtosis, ") is not significantly different from 0 (|t| = ", abs(t_kurtosis), "< 3.2). Outcome variable may be normal."))
  }
  
  ## Quantile-quantile plot; points should follow the reference line
  cat("\n 1.b \t Quantile-quantile plot:")
  QQPlot <- plot(dfModel,2, main = "1.b Quantile-Quantile plot")
  cat("\n \t\t If the data is normal, points on the Q-Q plot will follow the reference line.")
  # ggplot(df, aes(sample = y))+ stat_qq() + stat_qq_line()+ ggtitle("Q-Q Plot for interest in STEM") # alternative QQ plot
  ###
  
  ### Linearity and homoscedasticity ---
  ## residual plot
  cat("\n 2. Linearity and homoscedasticity.")
  cat("\n 2.a \t Residual plot:")
  residualPlot <- plot(STEMModel, 1, main = "2.a Residual plot") # x is fitted values, y is residuals
  # plot(dfModel, 3) # alternative to the plot above. Difference is that y-axis is the sqrt(abs(residuals))
  cat("\n \t\t If the data is linear, best fit of residuals (red line) should be linear.")
  cat("\n \t\t If the data is homoscedastic, range of residuals should be equivalent/comparable at all values of the 'fitted values' (i.e. y-hat).")
  ## 
  ###
  
  ### Multicollinearity ---
  ## Tolerance
  cat("\n 3. Testing multicollinearity: tolerance.")
  cat("\n if R^2 is high but there are few significant ")
  cat("\n 3.a \t Variance Inflation Factors:")
  vifPlot <- vif(dfModel, main = "3.a Variance Infation Factors")
  cat("\n \t\t If any VIF value is above 10, this indicates that the multicollinearity is not true.")
  
  ## correl matrix
  cat("\n 3.b \t Correlation matrix:")
  print(cor(df)) # cats correlation matrix of all the predictors
  cat("\n \t\t Ensure that all regression coefficients are insignificant predictors though overall model is significant.")
  cat("\n \t\t N.b. this is less formal than Tolerance and VIF analysis above.")
  ## check that all regression coefficients are insignificant predictors though overall model is significant -- though this is less formal
  ###
  
  ### Model correctly specified ----
  cat("\n 4 Correct specification of model.") 
  cat("\n 4.a \t Added-variable plots (aka partial-regression):")
  addedVarPlot <- avPlots(dfModel, main = "4.a Added-variable plots") # if slope is 0 then the predictor is not predicting unique variance in the model. SLope of lines should be equivalent to the regression coefs in the model.
  cat("\n \t\t The closer to 0 is the slope, the less unique variance this predictor is explaining in the model (slope of 0 = explaining no unique variance). N.b., Slope of lines is equivalent to the regression coefs in the model.")
  # summary(dfModel) # slope of line
  cat("\n \t\t Remove variable that is not predicting unique variance. Do so one at a time--excluding the one with a slope closest to 0 if applicable--and do so only at the end!")
  # !! only remove predictors at the end !!
  ###
  
  ### Outliers (i.e. influencers) ---
  cat("\n 5. Outlier analysis.")
  ## Evaluate influence
  cat("\n 5.a \t Evaluating influence.") 
  cat("\n 5.a.i \t\t Plot of Cook's distances:")
  cooksDistance <- plot(dfModel, 4, main = "5.a.i Cook's distance plot") # plot of Cook's distance
  cat("\n \t\t\t ") # Note what should be looked for.
  
  # Influence plot
  cat("\n 5.a.ii \t\t Influence Plot:")
  influencePlot <-influencePlot(dfModel, main="5.a.ii Influence Plot")
  cat("\n \t\t\t Consider removing the point(s) with large influence.") # Note what should be looked for.
  cat("\n \t\t\t Note. The larger the circle, the more influence the observation has. Studentized residuals indicate distance; hat-values indicate leverage") # Note what should be looked for.

  cat("\n 5.a.iii \t Influence Index Plot:")
  infIndex <- infIndexPlot(dfModel, main = "5.a.iii Influence Index Plot")
  
  allPlots <- 
    QQPlot + facet_wrap(~ carb, nrow = 1) + theme(legend.position = "none") +
    ggtitle("Test")
  
  # residualPlot, vifPlot, addedVarPlot, cooksDistance, influencePlot, infIndex

  # list(QQPlot, residualPlot, vifPlot, addedVarPlot, cooksDistance, influencePlot, infIndex)
  # list(plot(dfModel,2, main = "1.b Quantile-Quantile plot"), plot(STEMModel, 1, main = "2.a Residual plot"),vif(dfModel, main = "3.a Variance Infation Factors"),avPlots(dfModel, main = "4.a Added-variable plots"), plot(dfModel, 4, main = "5.a.i Cook's distance plot"),influencePlot(dfModel, main="5.a.ii Influence Plot"), infIndexPlot(dfModel, main = "5.a.iii Influence Index Plot"))
}
```

### Normality

```{r normalityCheck, echo=FALSE}
normalityCheck <- function(df, y, toPrint){  
  
  if(is.character(y)){
    colNumofY <- which(colnames(df) == y)
  } else if (is.numeric(y)){
    colNumofY <- y
  }
  
  degFree <- length(df[[colNumofY]])
  
  skew <- skew(df[[colNumofY]]) # N.b., the double square brackets '[[]]' is ESSENTIAL for getting the correct results--single brackets '[]' will return inaccurate results.
  SE_skew <- sqrt(5/degFree) # Standard error for skewness
  t_skew <- skew/SE_skew
  p_skew <- pt(q = abs(t_skew), df = degFree, lower.tail = TRUE)
  
  kurtosis <- kurtosi(df[[colNumofY]])
  SE_kurtosis <- sqrt(24/degFree) # Standard Error for the kurtosis
  t_kurtosis <- kurtosis/SE_kurtosis
  p_kurtosis<- pt(q = abs(t_kurtosis), df = degFree, lower.tail = TRUE)
  
    out <- data.frame(. = c("skew", "kurtosis"),
                      value = c(skew,kurtosis),
                      SE = c(SE_skew,SE_kurtosis),
                      t = c(t_skew,t_kurtosis),
                      p = c(p_skew,p_kurtosis),
                      issue = c(ifelse(abs(t_skew)>3.2, 1, 0),ifelse(abs(t_kurtosis)>3.2, 1, 0)))
  
  if(toPrint == TRUE){
    cat(paste("Assumption tests for the given data and model with dependent variable '", colname(df[colNumOfY]), "'"))
    cat("\n 1. Normality.") 
    cat("\n 1.a \t Skew and kurtosis.")
    if(abs(t_skew) > 3.2){ # checks if the t-value for skewness is greater than the critical t-value 
      cat(paste("\n \t\t !! Skewness (", skew, ") is significantly different from 0 (|t| = ", abs(t_skew), "> 3.2). Outcome variable is not normal."))
    } else {
      cat(paste("\n \t\t Skewness (", skew, ") is not significantly different from 0 (|t| = ", abs(t_skew), "< 3.2). Outcome variable may be normal."))
    }
  
    if(abs(t_kurtosis) > 3.2){ # checks if the t-value for kurtosis is greater than the critical t-value 
      cat(paste("\n \t\t !! Kurtosis (", kurtosis, ") is significantly different from 0 (|t| = ", abs(t_kurtosis), "> 3.2). Outcome variable is not normal."))
    } else {
      cat(paste("\n \t\t Kurtosis (", kurtosis, ") is not significantly different from 0 (|t| = ", abs(t_kurtosis), "< 3.2). Outcome variable may be normal."))
    }
  }
  
  return(out)
} # 'df' - dataframe; 'y' - variable of interest; 'toPrint' - logical specifying if should print messages regarding the normality. Output is a 3 x 6 df with rows 0: column names, 1: 'skew', 2: 'kurtosis'; and columns: 0: '.', 1: 'value', 2: 'SE', 3: 't', 4: 'p', 5: 'issue'
```

```{r normalityCorrections, echo=FALSE}
normCorrection <- function(df, xName, correctionType){
  xColNum <- which(colnames(df) == xName)
  if(correctionType == "tert"){
    tertileValues <- quantile(df[xColNum], c(0:3/3), na.rm = T) # find tertile values
    newColName <- glue(xName, "_tert")
    df <- df %>% 
      mutate_(newColName = cut({{ xName }},
                       breaks = .tertileValues,
                       labels = FALSE,
                       include.lowest = T), 
             .after = {{ xName }})
    cat(paste("The tertiles for ", xName, "are: \n\t", tertileValues))
  } else if (correctionType == "log") {
    newColName <- glue(xName, "_log")
    df <- df %>% 
      mutate(newColName = log(df[xColNum]), .after = xName)
  } else {
    cat(paste("Error. '", correctionType, "' is not a valid correction type. Accepted values are: \n\t'tert' for tertiles; \n\t'log' for logarithmic. \nNo changes were made to the dataframe for the variable ", xName, "."))
  }
  return(df)
} # takes df: dataframe; xName: name of the variable to correct; correctionType: how the variable should be corrected (possible values: 'tert' tertile, 'log' logarithmic. Returns df with the corrected variable after the original variable.
```

### Linearity

```{r linearityChecks, echo=FALSE}

```

### Homoscedasticity

```{r homoscCheck, echo=FALSE}

```

## Assumption corrections

## Comparative analyses

!! Have yet to write out TTest function !!

```{r runStatTests, echo=FALSE}
runTTest <- function(vars, df_a, df_b, toSave){
  
} # 'vars' - list of numeric variables to compare; 'df_a' - dataframe with subset of cases; 'df_b' - dataframe with subset to compare to; 'toSave' - logical if the output should be saved to a file. Returns TTest output.

runWilcox <- function(vars, df_a, df_b, toSave){
    wilcoxOutput <- data.frame("value type" = c("statistic","p", "n1", "n2"), row.names = 1) # initialize dataframe for the output
    i <- integer(0)
    for(i in vars){ # iterate through the variables of interest. Run wilcoxon-paired rank test. Put results into a dataframe 
      # print(i)
      x <- as.numeric(unlist(df_a[i])) # put variable {i} of df_a into a temporary vector, make numeric.
      y <- as.numeric(unlist(df_b[i])) # put variable {i} of df_b into a temporary vector, make numeric.
      
      n1 <- sum(!(is.na(x))) # counts number of non-NA values in x
      n2 <- sum(!(is.na(y))) # counts number of non-NA values in y
      
      if(n1 <= 1 | n2 <= 1){
        print(paste("Not enough observations to compare ", i, ". This variable was skipped."))
      } else {
        wilcoxRaw <- wilcox.test(x, y, alternative = c("two.sided"), paired = F) # run wilcoxon paired-rank
        wilcoxStat <- format(wilcoxRaw$statistic, scientific = F, digits = 3) # Extract W statistic of test. N.b., the 'W' statistic reported here is equivalent to the U statistic: https://stats.stackexchange.com/questions/79843/is-the-w-statistic-output-by-wilcox-test-in-r-the-same-as-the-u-statistic
        wilcoxP <- format(wilcoxRaw$p.value, scientific = F, digits = 3) # Extract P statistic of test
        wilcoxInterest <- c(wilcoxStat, wilcoxP, n1, n2) # combine W statistic, p, n1 and n2 into a vector
        wilcoxOutput[[i]] <- with(wilcoxOutput, wilcoxInterest) # Add the results for variable {i} to the output dataframe
        # print(wilcoxInterest)
      }
    }
    if(toSave == T | toSave == TRUE){
      setwd(outputPath)
      outputNameWilcox <- str_c("UKBBImmuCog_wilcoxon_", date, ".csv")
      write.csv(wilcoxOutput, file = outputNameWilcox) # exports wilcoxOutput to a CSV file
      print(paste("The file '", outputNameWilcox, "' has been saved to '", getwd(), "'."))
    }
    return(wilcoxOutput)
} # 'vars' - list of numeric variables to compare; 'df_a' - dataframe with subset of cases; 'df_b' - dataframe with subset to compare to; 'toSave' - logical if the output should be saved to a file. Returns wilcoxon output.

runChiSq <- function(vars, df_a, df_b, toSave){ 
  chisqOutput <- data.frame("interv_compl" = c("statistic","p")) # initialize dataframe for the output
  
  for(i in vars){
    chisqRaw <- chisq.test(df_a[[i]], df_b[[i]]) # run chisquared
    chisqStat <- format(chisqRaw$statistic, scientific = F, digits = 3) # Extract X statistic of test.
    chisqP <- format(chisqRaw$p.value, scientific = F, digits = 3) # Extract P statistic of test
    varOfInterest <- c(chisqStat, chisqP) # combine X statistic, and p into a vector
    chisqOutput[[i]] <- with(chisqOutput, varOfInterest) # Add the results for "dem_gender" to the output dataframe
  }

  if(toSave == T | toSave == TRUE){
    setwd(outputPath)
    outputNameChisq <- str_c("UKBBImmuCog_chisq_", date, ".csv")
    write.csv(wilcoxOutput, file = chisqOutput) # exports chisqOutput to a CSV file
    print(paste("The file '", chisqOutput, "' has been saved to '", getwd(), "'."))
  }
  return(chisqOutput)
} # 'vars' - list of categorical variables to compare; 'df_a' - dataframe with subset of cases; 'df_b' - dataframe with subset to compare to; 'toSave' - logical if the output should be saved to a file. Returns chisq output.
```

## PCA function

!! Variables are not being identified as numeric !!

```{r PCAFx, echo=FALSE}
PCACompute <- function(df, vars){
  # PCA (see 536 lecture notes week 10) ---------
  rejectVars <- c()
  for(i in vars){
    if(is.numeric(as.matrix(df[[i]])) == FALSE){ # checks that variables are numeric
        rejectVars <- append(rejectVars, i)
    } else {
        mean <- mean(as.matrix(df[i]), na.rm = T)
        sd <- sd(as.matrix(df[i]), na.rm = T)
        
        if(round(mean,4) != 0 || round(sd,4) != 1){ # check if standardized
          df[i] <- scale(df[i])
          # print(c("Not standard.",colnames(df[i]), typeof(as.matrix(df[i])))) 
          # print(c(mean(as.matrix(df[i]), na.rm = T), sd(as.matrix(df[i]), na.rm = T)))
        } else {
          # print(c("Yes.",colnames(df[i]), typeof(as.matrix(df[i]))))   
          # print(c(mean(as.matrix(df[i]), na.rm = T), sd(as.matrix(df[i]),na.rm = T)))
        }
    }
  }
  
  if(length(rejectVars) > 0){
      cat("The following variables are not numeric and cannot be included in PCA. \n\t")
      for(i in colnames(df[rejectVars])){
        cat(i, "\t")
      }
     vars <- vars[vars %in% rejectVars == FALSE] # removes the reject variables from the 'vars' list
  }
  
  out <- prcomp(as.matrix(df[,vars]), center = TRUE, scale = TRUE) # prints output
  return(out)
  
} # 'df' - dataframe; 'vars' - name of vars to conduct PCA on. N.B. these variables must be standardized before being entered here.

PCAPlot <- function(PCAOut, name){
  require(factoextra)
  
  screePlot <- fviz_eig(PCAOut,
                  choice = c("eigenvalue"),
                  geom = c("line"),
                  linecolor = "black",
                  ncp = 10,
                  addlabels = TRUE,
                  hjust = 0,
                  main = paste("Scree plot - ", name),
                  xlab = "Principal component",
                  ylab = NULL) +
              geom_hline(yintercept = 1, linetype = 2)

  return(screePlot)

} # 'PCAOut' - an object of class PCA (i.e., from the PCA compute function); 'name' - name of this PCA analysis

PCAApply <- function(df, PCAOut, componentsToRetain, prefix){
  
  varCols <- which(colnames(df) %in% names(PCAOut$rotation[,1]))
  df_z <- df %>% 
    as_tibble() %>% 
    mutate_at(varCols, ~(scale(.) %>% as.vector))
  
  for(i in 1:componentsToRetain){
    rowName <- paste(prefix, "PC", i, sep="_")
    df_z <- df_z %>% 
      mutate("{rowName}" := as.matrix(df_z[varCols]) %*% PCAOut$rotation[,i])
  }
  
  return(df_z)
  
} # Gives each observation a score for each PCA component retained. 'df' - dataframe; 'PCAOut' - output from the PCACompute function; 'componentsToRetain' - an integer value specifying the number of principal components to retain (value must be between 1 and total number of components)); 'prefix' - a character string to be used as a prefix for the new column names.

PCASave <- function(PCAOut, fileName){
  capture.output(PCAOut$rotation, file = paste(fileName, date, ".csv", sep=""), row.names=FALSE)
  print("The file ", fileName, "was saved to '", getwd(), "'.")
}
  
```

## Function to make appropriate expression for stats::LM functions

```{r LMexpressionFunction, echo=FALSE}
createLMExpression <- function(varNames, X, Y, M, C){
  colNumsPredictors <- c()
  for(i in c(X, M, C)){
    if(i != "ignore"){
      colNum <- which(varNames == i)
      # print(i)
      colNumsPredictors <- append(colNumsPredictors, colNum)
    }
  } # get column numbers for the relevant predictor variables

  LMpredictors <- paste(sapply(varNames[colNumsPredictors], paste), collapse = " + ")
  model <- paste(Y, " ~ ", LMpredictors, sep = "")
  return(model)
} # Input: 'varNames' - list of variable names in the dataframe to be analysed. Is given by the function colnames(df); 'Y' - name of the dependent variable; 'X' - name of the independent variable; 'M' - name of mediators mediators; 'C' - list of covariate variable names;
```

```{r LMexpressionSandBox, echo=FALSE}
varNames = colnames(df)
X <- "crp_aliquot_fctr" # name of independent variable
Y <- "cog_PC_1" # name of dependent variable
M <- "brain_vol_brainSegNoVent_t2"
C <- c("demo_sex_t0", "ses_townsend_t0", "crp_hourCollected")
df$brain_vol_brainSegNoVent_t2
colNumsPredictors <- c()
for(i in c(X, M, C)){
    if(i != "ignore"){
      colNum <- which(varNames == i)
      print(i)
      colNumsPredictors <- append(colNumsPredictors, colNum)
    }
  } # get column numbers for the relevant predictor variables
which(varNames == M)
toString(paste(varNames[colNumsPredictors], "+ ", collapse = ""))
?collapse
paste(sapply(varNames[colNumsPredictors], paste), collapse = " + ")
createLMExpression(varNames, X = X, Y = Y, M = M, C = C)
runMediation(varNames, X = X, Y = Y, M = M, C = C)

```
## Correlation analyses functions

## Mediation Analyses

### Using package: mediation

```{r mediationFunction, echo=FALSE}
# where M: continuous mediator; X: independent variable; Y: continuous dependent variable; C: covariates
runMediation <- function(df, X, Y, M, C, mediatorModelExpression, outcomeModelExpression, control){
  require(mediation)

  # mediatorModelExpression <- createLMExpression(varNames = colnames(df), X = X, Y = M, M = NULL, C = C) # mediator model: predict M from X and C
  # outcomeModelExpression <-  createLMExpression(varNames = colnames(df), X = X, Y = Y, M = M, C = C) # outcome model: predict Y from X, M and C
  # print(mediatorModelExpression)
  # print(outcomeModelExpression)
  
   if(is.factor(X) != TRUE){
    control <- NULL
  }
  mediatorModel <- lm(eval(parse(text = mediatorModelExpression)), data = df) 
  outcomeModel <- lm(eval(parse(text = outcomeModelExpression)), data = df)
  mediation_out <- mediation::mediate(mediatorModel, outcomeModel, treat = X, control = control, mediator = M, covariates = C, boot = T)
  return(mediation_out)
} # This function runs the mediation analyses and returns the mediation model. Input: 'df' - dataframe; 'X' - name of independent variable; 'Y' - name of dependent variable; 'C' - a list of covariate variable names in string form;  'mediatorModelExpression' - the model predicting M from X and C; 'outcomeModelExpression' - the model predicting Y from X, M and C; 'treat' - the level of X to be used as the reference group, leave NULL if X is continous
```

### Using package: RMediation

```{r RMediationFunction, echo=FALSE}
# see psyc 536 lecture 5 notes
runRMediation <- function(df, X, Y, M, C){
  require(RMediation)
  
  totModelExpression <- createLMExpression(varNames = colnames(df), X = X, Y = Y, M = "", C = C) # total model: predict Y from X and C
  aPathExpression <- createLMExpression(varNames = colnames(df), X = X, Y = M, M = "", C = C) # a path model: predict M from X and C
  bPathExpression <- createLMExpression(varNames = colnames(df), X = X, Y = Y, M = M, C = C) # b path & direct path model: predict Y from X, M, and C
  
  # total effect
  totModel <- lm(eval(parse(text = totModelExpression)), data = df)
  cat("'total model' linear model expression: \n\t", totModelExpression)
  print(summary(totModel))
  
  # a path -- predict M from X
  aModel <- lm(eval(parse(text = aPathExpression)), data = df)
  cat("'a path' linear model expression: \n\t", aPathExpression)
  print(summary(aModel))
  
  # b path -- predict Y from X, M and C
  bModel <- lm(eval(parse(text = bPathExpression)), data = df)
  cat("'b path' linear model expression: \n\t", bPathExpression)
  print(summary(bModel))
  
  a <- coef(aModel)[which(names(coef(aModel)) == X)] # want coef for effect of X on M
  a.se <- coef(summary(aModel))[which(names(coef(aModel)) == X),2] # want S.E. of the regression coef of X on M. N.b. index is [row of X, column of standard errors of estimate]
  b <- coef(bModel)[which(names(coef(bModel)) == M)] # want coef for effect of M on Y
  b.se <- coefficients(summary(bModel))[which(names(coef(bModel)) == M),2] # want coef for effect of M on Y
  
  medci(mu.x = a, mu.y = b, se.x = a.se, se.y = b.se, rho = 0, alpha = .05, plot = T, plotCI = T)
  #format output somehow
} # input: 'df' - dataframe containing all relevant variables; 'X' - name of the predictor variable; 'Y' - name of the outcome variable; 'M' - name of the mediator variable; 'C' - list of names of covariate variables
```

### Functions for figures and tables

#### Scatterplots

```{r createPlot, echo=FALSE}
# createPlot <- function(df, x, y, xUnits, yUnits, title, loessLine, fileName){
#   require(ggplot2)
#   
#   xColNum <- which(colnames(df)==x)
#   yColNum <- which(colnames(df)==y)
#   
#   plot <- ggplot(data = df, aes(x=df[xColNum], y=df[yColNum], colour = rgb(.1,.1,.1,.7))) +
#     geom_count() +
#     labs(title = title, x = paste(x, " (", xUnits, ")"), y = paste(y, " (", yUnits, ")"))
#   
#   if(loessLine == T | loessLine == "y" | loessLine == "yes"){
#     plot <- plot + geom_smooth(method='loess')
#   }
#     
#   if(nchar(fileName) != 0){
#     fileName <- paste(fileName, ".png")
#     ggsave(fileName, width = 5, height = 5)
#   }
#   return(plot)
# } # 'df' - dataframe; 'x' - indeped var; 'y' - dep var; 'xUnits' - units of variable 'x'; 'yUnits' - units of variable 'y'; 'title' - title for the graph; 'loessLine' - logical, if the Loess line should be shown, 'fileName' - specifies name to save file to without file extension, if do not want to save, specify ""
```

```{r scatterPlotSandBox, echo=FALSE}

# createPlot(df, x=diet_rawVeg_t0, y=diet_cookedVeg_t0, xUnits = "pieces/day", yUnits = "tbsp/day", title = "CookedVeg vs rawVeg", loessLine = TRUE, fileName = "")
# 
# "diet_cookedVeg_t0"
# df$diet_cookedVeg_t0
# df$diet_rawVeg_t0
# 
# x <- 
# xUnits <- 
# y <- which(colnames(df)=="diet_cookedVeg_t0")
# yUnits <- 
# title <- "A plot"
# library(ggplot2)
# 
# plot <- ggplot(data = df, aes(x=diet_rawVeg_t0, y=diet_cookedVeg_t0, colour = rgb(.1,.1,.1,.7))) +
#     geom_count() +
#     labs(title = title, x = paste("diet_rawVeg_t0", " (", xUnits, ")"), y = paste("diet_cookedVeg_t0", " (", yUnits, ")"))
# plot <- plot + geom_smooth(method='loess')
# xlab() + ylab() + name = title

```

#### Mediation diagrams

!! Needs to be revised !!

```{r medAnalysisFx, echo=FALSE}
# adapted from Omar Wasow's post on https://stackoverflow.com/questions/46465752/drawing-simple-mediation-diagram-in-r
med_data <- data.frame(
    lab_x   = "Math\\nAbility",
    lab_m   = "Math\\nself-efficacy",
    lab_y   = "Interest in the\\nmath major",
    coef_xm = ".47*",
    coef_my = ".36*",
    coef_xy = "0.33* (.16)"
  )

med_diagram <- function(data){
  
  require(glue)
  require(DiagrammeR)
  
  height = .75
  width = 2
  graph_label = NA
  node_text_size = 12
  edge_text_size = 12
  color = "black"
  ranksep = .2
  minlen = 3
  
  data$height  <- height   # node height
  data$width   <- width    # node width
  data$color   <- color    # node + edge border color
  data$ranksep <- ranksep  # separation btwn mediator row and x->y row
  data$minlen  <- minlen   # minimum edge length
  
  data$node_text_size  <- node_text_size
  data$edge_text_size  <- edge_text_size
  
  data$graph_label <- ifelse(is.na(graph_label), "", paste0("label = '", graph_label, "'"))

  diagram_out <- glue::glue_data(data,
    "digraph flowchart {
        fontname = Helvetica
        <<graph_label>>
        graph [ranksep = <<ranksep>>]
  
        # node definitions with substituted label text
        node [fontname = Helvetica, shape = rectangle, fixedsize = TRUE, width = <<width>>, height = <<height>>, fontsize = <<node_text_size>>, color = <<color>>]        
          mm [label = '<<lab_m>>']
          xx [label = '<<lab_x>>']
          yy [label = '<<lab_y>>']
  
        # edge definitions with the node IDs
        edge [minlen = <<minlen>>, fontname = Helvetica, fontsize = <<edge_text_size>>, color = <<color>>]
          mm -> yy [label = '<<coef_my>>'];
          xx -> mm [label = '<<coef_xm>>'];
          xx -> yy [label = '<<coef_xy>>'];
        
        { rank = same; mm }
        { rank = same; xx; yy }
        
        }
        ", .open = "<<", .close = ">>")  


  DiagrammeR::grViz(diagram_out)  
}

med_diagram(med_data)
```

# -------------------------------

# 1 - Biobank data analysis

## Data Preperation

```{r removeEIDs, echo=FALSE}
# df_all <- read_csv("/home/doodlefish/Documents/Research/LepageLab/immunologyAndSz/Data/CCData/Daniel_2022-03-17.csv") # import df
# eidToRemove <- read_csv("/home/doodlefish/Documents/Research/LepageLab/immunologyAndSz/Data/CCData/eidToRemove-w45551_20220222.csv", col_names = "eid") # file with EID of participants who withdrew consent from UKBB
# 
# df_all <- df_all %>% filter(!(eid %in% eidToRemove)) # remove rows with eid in this file
# write.csv(df_all, "/home/doodlefish/Documents/Research/LepageLab/immunologyAndSz/Data/CCData/Daniel_2022-03-17_ProperEID.csv", row.names=FALSE)
# rm(df_all, eidToRemove) # remove dataframes not in use

```

```{r dataPrep, echo=FALSE}
df_all <- read_csv("/home/doodlefish/Documents/Research/LepageLab/immunologyAndSz/Data/CCData/Daniel_2022-03-17_ProperEID.csv", guess_max = 10000) # import df
         
cat(paste("There are ", sum(is.na(df_all$date_assess2_t2)), "cases that have not completed time point 2. These cases will be removed."))
df_all <- df_all %>% 
  filter(!(is.na(df_all$date_assess2_t2))) # remove rows without timepoint 2 assessment date

df <- df %>% 
  transform(sleep_duration2_t2 = as.character(sleep_duration2_t2))

typeof(df$sleep_duration2_t2)
df_small <- df_all[1:1000,]
df <- df_small # specifies what df to use. In final analyses will want to use df_all but want to use smaller df while developing code.
rm(df_small) # remove dataframes not in use
# sort(colnames(df))
# View(df)
```

```{r removeTMTErrorBefore, echo=FALSE}
# cogToRemove <- contains("ErrorsBeforeCor_t2_", vars = colnames(df))
# # colnames(df[cogToRemove])
# df <- df[,-cogToRemove]

```

```{r standardizeErrors, echo=FALSE}
# standardize error codes
df <- df %>%
  mutate(diet_cookedVeg_t0 = case_when(  # for field: 1289 ('diet_cookedVeg'), -10 = Less than one; -1 = Do not know; -3 = Prefer not to answer;  
      diet_cookedVeg_t0 == "Less than one" ~ "0.5",       
      diet_cookedVeg_t0 == "Do not know" ~ "NA",       
      diet_cookedVeg_t0 == "Prefer not to answer" ~ "NA",
      TRUE ~ diet_cookedVeg_t0
  )) %>% 
  mutate(diet_fruit_t0 = case_when( # for field: 1309 ('diet_fruit'), -10 = Less than one; -1 = Do not know; -3 = Prefer not to answer;  
      diet_fruit_t0 == "Less than one" ~ "0.5",       
      diet_fruit_t0 == "Do not know" ~ "NA",       
      diet_fruit_t0 == "Prefer not to answer" ~ "NA",
      TRUE ~ diet_fruit_t0
  )) %>% 
  mutate(diet_rawVeg_t0 = case_when( # for field: 1299 ('diet_rawVeg'), -10 = Less than one; -1 = Do not know; -3 = Prefer not to answer;
      diet_rawVeg_t0 == "Less than one" ~ "0.5",       
      diet_rawVeg_t0 == "Do not know" ~ "NA",       
      diet_rawVeg_t0 == "Prefer not to answer" ~ "NA",
      TRUE ~ diet_rawVeg_t0
  )) %>%
  mutate(diet_processedMeat_t0 = case_when( # field 1349 ('diet_processedMeat'), -1 = Do not know; -3 = Prefer not to answer;
      diet_processedMeat_t0 == "Do not know" ~ "NA",       
      diet_processedMeat_t0 == "Prefer not to answer" ~ "NA",
      TRUE ~ diet_processedMeat_t0
  )) %>% 
  mutate(diet_water_t0 = case_when( # field 1528 ('diet_water'), -10 = Less than one; -1 = Do not know; -3 = Prefer not to answer;
      diet_water_t0 == "Less than one" ~ "0.5",       
      diet_water_t0 == "Do not know" ~ "NA",       
      diet_water_t0 == "Prefer not to answer" ~ "NA",
      TRUE ~ diet_water_t0
  )) %>%
  mutate(diet_alc_freq = case_when( # field 1558 ('cog_numMem_maxDigitRemem_t2'), -3 = Prefer not to answer;
    cog_numMem_maxDigitRemem_t2 == "Prefer not to answer" ~ "NA",
    TRUE ~ cog_numMem_maxDigitRemem_t2 
    )) %>% 
  mutate(menopause_t0 = case_when( # field 2724 ('menopause'), -3 = Prefer not to answer;
      menopause_t0 == "Prefer not to answer" ~ "NA",
      TRUE ~ menopause_t0
  )) %>%
  mutate(sleep_duration0_t0 = case_when( # field 1160 ('sleep_duration'), -1 = Do not know; -3 = Prefer not to answer;
      sleep_duration0_t0 == "Prefer not to answer" ~ "NA",
      sleep_duration0_t0 == "Do not know" ~ "NA",
      TRUE ~ sleep_duration0_t0
  )) %>%
  mutate(sleep_duration2_t2 = case_when( # field 1160 ('sleep_duration'), -1 = Do not know; -3 = Prefer not to answer;
      sleep_duration2_t2 == "Prefer not to answer" ~ "NA",
      sleep_duration2_t2 == "Do not know" ~ "NA",
      TRUE ~ sleep_duration2_t2
  )) %>%
   mutate(smoke_currently_t0 = case_when( # field 2724 ('smoke_currently'), -3 = Prefer not to answer;
      smoke_currently_t0 == "Prefer not to answer" ~ "NA",
      TRUE ~ smoke_currently_t0
  )) %>%
  mutate(cog_TMT_numericDuration_t2 =  case_when( # fields: 6348 ('cog_TMT_numericDuration'), 6350 ('cog_TMT_alphanumDuration'), 0 = trail not completed
    cog_TMT_numericDuration_t2 == "trail not completed" ~ "NA",
    TRUE ~ cog_TMT_numericDuration_t2
  )) %>% 
  mutate(cog_TMT_alphanumDuration_t2 =  case_when(
    cog_TMT_alphanumDuration_t2 == "trail not completed" ~ "NA",
    TRUE ~ cog_TMT_alphanumDuration_t2
  )) %>% 
  mutate(cog_numMem_maxDigitRemem_t2 = case_when( # field 4282 ('cog_numMem_maxDigitRemem_t2'), -1 = abandoned
    cog_numMem_maxDigitRemem_t2 == "abandoned" ~ "NA",
    TRUE ~ cog_numMem_maxDigitRemem_t2
  )) 

```

### Add columns

#### Waist:Hip ratio

```{r waistToHip, echo=FALSE}

df <- df %>% 
  mutate("waistToHip" = weight_waistCirc_t0/weight_hipCirc_t0)

```

#### Add columns for any diagnosis or medication

```{r anyDxMedColumns, echo=FALSE}
# Create column identifying if have any diagnoses of interest or medication of interest  -------------------------
## Diagnosis
dxVars <- starts_with("dx_", vars = colnames(df))
df <- df %>% 
  mutate("anyDxOfInterest" = case_when(
    if_any(any_of(dxVars), function(x) (x == "TRUE")) ~ 1,
    if_all(all_of(dxVars), function(x) (x == "FALSE")) ~ 0
  ))
# table(df$anyDx)

## Medication
medVars <- starts_with("med_", vars = colnames(df))
medVars0 <- ends_with("0", vars = colnames(df[medVars]))
medVars0 <- which(colnames(df) %in% colnames(df[medVars[medVars0]]))

medVars2 <- ends_with("2", vars = colnames(df[medVars]))
medVars2 <- which(colnames(df) %in% colnames(df[medVars[medVars2]]))

df <- df %>% 
  mutate("anyMedOfInterest0" = case_when(
    if_any(any_of(medVars0), function(x) (x == "TRUE")) ~ 1,
    if_all(all_of(medVars0), function(x) (x == "FALSE")) ~ 0
  )) %>% 
  mutate("anyMedOfInterest2" = case_when(
    if_any(any_of(medVars2), function(x) (x == "TRUE")) ~ 1,
    if_all(all_of(medVars2), function(x) (x == "FALSE")) ~ 0
  ))
# table(df$anyMed)
```

#### Add column for time of day cognitive assessments, MRI completed

!! difference between two columns is of list type for some reason, thus cannot be described. Must be fixed. !!

```{r assessmentHour, echo=FALSE}
# Goal: take variables with form: 'YYYY-MM-DDTHH:MM:SS' and return the hour
df <- df %>% 
  mutate(crp_hourCollected = hour(df$crp_timeCollected_t0)) %>% 
  mutate(cog_hourCompleted = hour(df$cog_timeCompleted_t2)) %>% 
  mutate(brain_hourCompleted = hour(df$brain_timeCompleted_t2))

# df <- df %>% mutate(timeDif_brainHourMinusCogHourCompleted = df[124] - df[123]) # number of hours difference between cognitive assessment and MRI

hourColNums <- c(contains("_hourCompleted", vars = colnames(df)),contains("_hourCollected", vars = colnames(df)))

```

### Prospective memory - dichotimize to correct in first attempt or not (as in Cullen et al., 2017)

```{r prospMemRecode, echo=FALSE}
df <- df %>% 
  mutate(cog_prospMem_result_t2 = case_when( # field 20018 ('cog_prospMem_result_t2'), 0 = instruction not recalled, either skipped or incorrect; 1 = correct recall on first attempt; 2 = correct recall on second attempt
    cog_prospMem_result_t2 == "correct recall on first attempt" ~ "correct on first",
    TRUE ~ "incorrect on first" 
    ))

```

### CRP cutoffs (see Pearson et al., 2003)
```{r CRPRecode, echo=FALSE}
df <- df %>% 
      mutate(crp_aliquot_fctr = cut(crp_aliquot_t0,
                       breaks = c(0,1,3, 10),
                       labels = c("low", "avg", "high"),
                       include.lowest = T,
                       right = F), .after = crp_aliquot_t0)
sum(table(df$crp_aliquot_fctr))

```

### Make columns appropriate data types

```{r colType, echo=FALSE}
df <- readr::type_convert(df) # automatically detect

factorVars <- which(colnames(df) %in% c("demo_sex_t0", "demo_ethnicity_t0", "cog_prospMem_result_t2", "hand_t0", "smoke_ever_t0", "menopause_t0", "anyMedOfInterest", "anyDxOfInterest")) # Factors
df[,factorVars] <- lapply(df[,factorVars], factor) # at this line the df size is read as 0 B for some reason. This does not appear to affect the data however.

# ordinalVars <- which(colnames(df) %in% c("smoke_currently_t0", "diet_processedMeat_t0", "exercise_IPAQActivityGroup_t0")) # ordinal variables
df <- df %>% 
  mutate(smoke_currently_t0 = factor(smoke_currently_t0, order = T,
                                     levels = c("No", 
                                                "Only occasionally", 
                                                "Yes, on most or all days")
                                     )) %>% 
  mutate(diet_processedMeat_t0 = factor(diet_processedMeat_t0, order = T,
                                     levels = c("Never", 
                                                "Less than once a week",
                                                "Once a week",
                                                "2-4 times a week",
                                                "5-6 times a week",
                                                "Once or more daily")
                                     )) %>% 
  mutate(diet_alc_freq = factor(diet_alc_freq, order = T,
                                     levels = c("Never",
                                               "Special occasions only",
                                               "One to three times a month",
                                               "Once or twice a week",
                                               "Three or four times a week",
                                               "Daily or almost daily")
                                     )) %>% 
  mutate(exercise_IPAQActivityGroup_t0 = factor(exercise_IPAQActivityGroup_t0, order = T,
                                     levels = c("low", 
                                                "moderate",
                                                "high")
                                     ))

```

## Remove cases with missing variables
```{r variableLists, echo=FALSE}
demoVars <- starts_with("demo_", vars = colnames(df))
crpAliqVars <- starts_with("crp_aliquot", vars = colnames(df))
brainVolVars <- starts_with("brain_vol", vars = colnames(df))
cogVars <- starts_with("cog_", vars = colnames(df))

dietVars <- starts_with("diet_", vars = colnames(df))

smokingVars <- starts_with("smoke_", vars = colnames(df))
exerciseVars <- starts_with("exercise_", vars = colnames(df))

completionTimeVars <- c(contains("timeCompleted", vars = colnames(df)), contains("timeCollected", vars = colnames(df)))
cogPCAVars <- which(colnames(df) %in% c("cog_numMem_maxDigitRemem_t2", "cog_TMT_numericDuration_t2", "cog_TMT_numericErrors_t2", "cog_TMT_alphanumDuration_t2", "cog_TMT_alphanumErrors_t2", "cog_matrix_cor_t2", "cog_fluidIntel_score_t2", "cog_reactiontime_mean_t2", "cog_tower_cor_t2", "cog_digsub_cor_t2"))

# colnames(df[completionTimeVars])
# View(df[1:100, c(1,cogPCAVars)])
```

```{r removeMissing, echo=FALSE}
essentialVars <- c(demoVars, completionTimeVars, crpAliqVars, cogPCAVars, brainVolVars) # list of variable names that must be complete in order for case to be retained

df_removed <- df %>% 
  filter(if_any(any_of(essentialVars), function(x)(is.na(x)))) # add rows with missing values to new df
# View(df_removed)
df_remaining <- df %>% 
  filter(!(eid %in% df_removed$eid)) # remove rows of those with missing values

df <- df_remaining

# View(df[cogVars])

```

Critical variables: `r colnames(df[essentialVars])` `r nrow(df_removed)` unique cases have missing values for critical variables and will thus be removed.

```{r missingValues, echo=FALSE}
numMissing <- matrix(ncol=1, nrow = length(essentialVars), dimnames = list(colnames(df_removed[essentialVars]),c("NACount")))

for(i in 1:length(essentialVars)){
  numMissing[i,] <- c(sum(is.na(df_removed[essentialVars[i]])))
}

numMissing_df <- as.data.frame(numMissing) %>%  arrange(desc(NACount))
kable(numMissing_df)

```

### Summarise removed cases

```{python describeDf_Removed, echo=FALSE}
# df_described = descriptiveStats(r.df, toSave = False)
# df_removed_described = descriptiveStats(r.df_removed, toSave = False)
```

### Compare removed cases to retained cases

```{r compareMissing, echo=FALSE}
varsToCompare <- c(demoVars, crpAliqVars, brainVolVars, dxVars, medVars, dietVars, smokingVars, exerciseVars)
varsToCompare <- c(smokingVars, medVars, which(colnames(df) == "crp_timeFasting_t0"))
# group variables according to their type, i.e., numeric vs categorical.
varForT <- c() # compute t-tests if vars are normally distributed
varForWil <- c() # wilcox if vars are not normally distributed
varForChi <- c() # chisq if vars are categorical

i <- which(colnames(df) == "crp_timeFasting_t0")
is.numeric(i)
normCheck <- normalityCheck(df, i, FALSE)
colnames(df[[i]])
hist(df$crp_timeFasting_t0)
for(i in varsToCompare){
  if(is.numeric(df[[i]]) == TRUE & is.character(df[[i]]) == FALSE){  # if 'i' is a numeric variable
    normCheck <- normalityCheck(df, i, FALSE)
    if(1 %in% normCheck[[6]] == FALSE){ # if 'i' is not normally distributed
      varForT <- append(varForT, i)
      print(paste("Variable '", colnames(df[i]), "' added to t-test list."))
    } else {
      varForWil <- append(varForWil, i)
      print(paste("Variable '", colnames(df[i]), "' added to wilCox list."))
    }
  } else if (is.factor(df[[i]]) == TRUE | is.logical(df[[i]]) | is.character(df[[i]]) == TRUE){ # if 'i' is a categorical variable
    varForChi <- append(varForChi, i)
    print(paste("Variable '", colnames(df[i]), "' added to chi-square list."))
  } else {
    print(paste("Variable '", colnames(df[i]), "' not added anywhere."))
  }
} # determine what test is most appropriate for each variable of interest.

runTTest(varForT, df, df_removed, FALSE)
runWilcox(varForWil, df, df_removed, FALSE)
# runChiSq(varForChi, df, df_removed, FALSE)

```

## Standardize appropriate columns

```{r standardizeData, echo=FALSE}
# varsToNotStandardize <- c("eid", "demo_birthYear", "ses_townend_t0", "cog_prospMem_timeDelay_t2", "smoke_packYears_t0", "demo_age_recruit_t0","brain_headScale_t2", "crp_aliquot_t0", "crp_hourCollected", "cog_hourCompleted", "brain_hourCompleted")
# as.data.frame(colnames(df[which(sapply(df[], is.numeric))]))

# df_z <- df %>% 
#   as_tibble() %>% 
#   mutate(across(where(is.numeric) %in% varsToNotStandardize), scale)

```

## Correlations between diet variables

```{r correlDietVars, echo=FALSE}
# cor(df[dietVars])

# summary(lm(df$diet_fruit_t0~df$diet_cookedVeg_t0))
# plot(df$diet_cookedVeg_t0, df$diet_fruit_t0)

```

```{r correlCRPVars, echo=FALSE}
cor(df$crp_hourCollected, df$crp_aliquot_t0)
plot(df$crp_aliquot_fctr, df$crp_hourCollected)
```

## Data reduction

-PCA assumptions: --linear relationship between components

```{r cognitionPCA, echo=FALSE}
df <- df_remaining
cogPCAOut <- PCACompute(df = df, vars = cogPCAVars)
typeof(cogPCAOut)
capture.output(unlist(cogPCAOut$rotation), fileName = paste("cognitionPCA_prelim", date, ".csv", sep = ""))

write.table(cogPCAOut$rotation, fileName = paste("cognitionPCA_prelim", date, ".csv", sep = ""))
lapply(cogPCAOut$rotation, function(x) write.table(data.frame(x), paste("cognitionPCA_prelim", date, ".csv", sep = "")))
PCASave(cogPCAOut, fileName = "cognitionPCA_prelim")
PCAPlot(PCAOut = cogPCAOut, name = "cognitionPCA")
```

The principal component analysis for the cognitive variables returns: `` {r} cogPCAOut` `` ```{r} summary(cogPCAOut)`

```{r applyCognitionPCA, echo=FALSE}

df <- PCAApply(df = df,PCAOut = cogPCAOut,componentsToRetain = 4,prefix = "cog")

```

# Analyses

## Descriptive Stats

```{r describeDf_r, echo=FALSE}
# describe(df)
```

```{python describeDf_py, echo=FALSE}
# descriptiveStats(r.df, toSave = False)
```

## Assumption checks

### Normality

#### Normality corrections

```{r normCorrections, echo = FALSE}
# df <- normCorrection(df, xName = "age_assess0_t0", correctionType = "tert")

```

!! Vars in code may need to be renamed !!

## Create subsets

```{r subsetCreation, echo=FALSE}
# Make different data subsets:
## N.b. should only subset when the main df has all the columns necessary for analysis
df_dx <- df %>% 
  group_by(across(any_of(dxVars))) %>% 
  summarize(median(crp_aliquot_t0))

df_noDx <- df %>% filter(anyDxOfInterest == 0) # remove participants with diagnoses from dataframe 
df_onlyDx <- df %>% filter(anyDxOfInterest == 1) # remove participants without diagnoses from dataframe 
df_noMed <- df %>% filter(anyMedOfInterest == 0) # remove participants taking meds from dataframe 
df_onlyMed <- df %>% filter(anyMedOfInterest == 1) # remove participants not taking meds from dataframe 
# df_old <- df %>% filter() # keeps only participants in the top tertile of age
# df_young <- df %>% filter() # keeps participants in the bottom tertile of age

```
## Run correlational analyses

!!! In outputs, specify what subset of participants it is for !!!

```{r corAnalyses, echo=FALSE}
# Correlations
## Models without covariates
cor()

plot(df$crp_aliquot_fctr, df$cog_PC_1)
plot(df$crp_aliquot_fctr, df$cog_PC_2)
plot(df$crp_aliquot_fctr, df$cog_PC_3)
plot(df$crp_aliquot_fctr, df$cog_prospMem_result_t2)
plot(df$crp_aliquot_fctr, df$cog_fluidIntel_score_t2)

ggplot(data=df, aes(x=brain_vol_brainSegNoVent_t2, y=cog_PC_1, color = crp_aliquot_fctr)) + geom_point()
ggplot(data=df, aes(x=brain_vol_brainSegNoVent_t2, y=cog_PC_2, color = crp_aliquot_fctr)) + geom_point()
ggplot(data=df, aes(x=brain_vol_brainSegNoVent_t2, y=cog_PC_3, color = crp_aliquot_fctr)) + geom_point()
ggplot(data=df, aes(x=brain_vol_brainSegNoVent_t2, y=cog_PC_4, color = crp_aliquot_fctr)) + geom_point()
df$brain_vol_hippocamp_L_t2

ggplot(data=df, aes(x=brain_vol_hippocamp_L_t2, y=, color = crp_aliquot_fctr)) + geom_point()

plot(df$cog_timeCompleted_t2, group = df$crp_aliquot_fctr)

cor0_noC <- lm(Y ~ X, data = df)
## Models with covariates
cor0 <- lm(Y ~ X + C, data = df)
```

## Mediation functions analyses

!! Will need to determine how to include covariate variables in this !! -- perhaps just include when (M \~ X) and when (Y \~ X + M) --As of March 12, 2022: uses all the covariates in the a path and the c path. See 'mediation: R package for Causal Mediation Analysis' (Tingley et al., 2014) For help with interpretation, see: PSYC 536 lab 5 script; <https://towardsdatascience.com/doing-and-reporting-your-first-mediation-analysis-in-r-2fe423b92171> \#\# Conduct analyses and return outputs

```{r sandBox, echo=FALSE}
X <- "crp_aliquot_fctr" # name of independent variable
Y <- "cog_PC_2" # name of dependent variable
M <- "brain_vol_brainSegNoVent_t2"
C <- c("demo_sex_t0", "ses_townsend_t0", "crp_hourCollected", "med_SSRI", "waistToHip", "exercise_IPAQActivityGroup_t0", "sleep_duration0_t0", "diet_alc_freq_t0", "demo_ethnicity_t0", "diet_processedMeat_t0") # add "demo_age_assess_t0", a diet variable

mediatorModelExpression <- createLMExpression(varNames = colnames(df), X = X, Y = M, M = NULL, C = C) # mediator model: predict M from X and C
outcomeModelExpression <-  createLMExpression(varNames = colnames(df), X = X, Y = Y, M = M, C = C) # outcome model: predict Y from X, M and C
mediation_out <- runMediation(df, X = X, control = NULL, Y = Y, M = M, C = C, mediatorModelExpression = mediatorModelExpression, outcomeModelExpression = outcomeModelExpression)
summary(mediation_out)

mediation_out <- runRMediation(df=df, X=X, Y=Y, M=M, C=C)

medsens(mediation_out, rho.by = .1, effect.type = "indirect")
plot(sensitivityAnalysis, sens.par = "R2", r.type = "total", sign.prod = "positive", main = M) # plots for R2. N.b. 'sign.prod', does the hypothesized confounder affect the mediator and outcome variables in the same direction or in different directions? If same then sign.prod = positive, else, = negative. See mediationR2 for details.
```

### Define model variables

```{r defineModel, echo=FALSE}
X <- "CRP_aliquot_t0" # name of independent variable
Y <- "cogGlobal" # name of dependent variable
C <- c("age_assess0", "BMI", "ses_townsend") # list of all covariate variables to control for
```

### Run mediation analyses

!!! In outputs, specify what subset of participants it is for !!! Interpretation of mediation::mediate function summary(): ACME (average causal mediation effect): indirect effect of IV on DV through the mediator. ADE (average direct effects): direct effect of IV on DV when controlling for the mediator and covariates. Total effect: effect of IV on DV through the mediator and through other (undefined) paths Prop mediate: proportion of the effect of IV on DV mediated by M.

```{r medAnalyses, echo=FALSE}
# Mediations
## Models without covariates
model0_noC <- runMediation(df = df, X = X, Y = Y, M = "brain_vol-brainSegNoVent", covars = "") # model between CRP, whole brain volume, general cog
model1a_noC <- runMediation(df = df, X = X, Y = Y, M = "brain_vol-hippocamp-L", covars = "") # model between CRP, L hippocamp, memory
model1b_noC <- runMediation(df = df, X = X, Y = Y, M = "brain_vol-hippocamp-R", covars = "") # model between CRP, L hippocamp, memory

## Models with covariates
model0 <- runMediation(df = df, X = X, Y = Y, M = "brain_vol-brainSegNoVent", covars = C) # model between CRP, whole brain volume, general cog
model1a <- runMediation(df = df, X = X, Y = Y, M = "brain_vol-hippocamp-L", covars = C) # model between CRP, L hippocamp, memory
model1b <- runMediation(df = df, X = X, Y = Y, M = "brain_vol-hippocamp-R", covars = C) # model between CRP, L hippocamp, memory

listMedModels <- c(model0_noC, model0, model1a_noC, model1a, model1b_noC, model1b)

# Get outputs for mediation analyses
for(i in listMedModels){
  summary(i)
  medsens(i, rho.by = .1, effect.type = "indirect")
  plot(sensitivityAnalysis, sens.par = "R2", r.type = "total", sign.prod = "positive", main = M) # plots for R2. N.b. 'sign.prod', does the hypothesized confounder affect the mediator and outcome variables in the same direction or in different directions? If same then sign.prod = positive, else, = negative. See mediationR2 for details.
}
```

!! Repeat above correlation and mediation analyses for each subgroup (i.e. with and with diagnoses, drugs...) !!

Session Info: `r sessionInfo()`
